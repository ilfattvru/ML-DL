{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtqmungyHe45H7DIuUgi0t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ilfattvru/ML-DL/blob/main/Titanic_kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Конкурс на Kagle\n",
        "Ссылка: https://www.kaggle.com/competitions/titanic/overview\n",
        "\n",
        "В работе использованы библиотеки pytorch, sklearn, numpy, pandas."
      ],
      "metadata": {
        "id": "wiffCQd1WVAG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zaMEV4wkBmgl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a634307-5b35-464b-c4de-482359c1f5f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# !pip install kaggle\n",
        "!pip install torch\n",
        "# !kaggle competitions download titanic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "train_df['Age'] = train_df['Age'].fillna(train_df['Age'].median())\n",
        "test_df['Age'] = test_df['Age'].fillna(test_df['Age'].median())\n",
        "test_df['Fare'] = test_df['Fare'].fillna(test_df['Fare'].median())\n",
        "train_df['Embarked'] = train_df['Embarked'].fillna('S')\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_df['Sex'] = label_encoder.fit_transform(train_df['Sex'])\n",
        "test_df['Sex'] = label_encoder.transform(test_df['Sex'])\n",
        "\n",
        "train_df = pd.get_dummies(train_df, columns=['Embarked'], drop_first=True)\n",
        "test_df = pd.get_dummies(test_df, columns=['Embarked'], drop_first=True)\n",
        "\n",
        "train_df = train_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
        "test_df = test_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
        "\n",
        "X = train_df.drop('Survived', axis=1)\n",
        "y = train_df['Survived']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train.values.astype('float32'))\n",
        "y_train_tensor = torch.tensor(y_train.values.astype('float32')).unsqueeze(1)\n",
        "X_val_tensor = torch.tensor(X_val.values.astype('float32'))\n",
        "y_val_tensor = torch.tensor(y_val.values.astype('float32')).unsqueeze(1)\n",
        "\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "class TitanicNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TitanicNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(X_train.shape[1], 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.sigmoid(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "model = TitanicNN()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.008)\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=20):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Validation step\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}')\n",
        "        model.train()\n",
        "\n",
        "def evaluate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            preds = (outputs >= 0.5).float()\n",
        "            predictions.extend(preds.numpy())\n",
        "            true_labels.extend(labels.numpy())\n",
        "    predictions = np.array(predictions)\n",
        "    true_labels = np.array(true_labels)\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    precision = precision_score(true_labels, predictions)\n",
        "    recall = recall_score(true_labels, predictions)\n",
        "    f1 = f1_score(true_labels, predictions)\n",
        "    roc_auc = roc_auc_score(true_labels, predictions)\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
        "\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=50)\n",
        "\n",
        "evaluate_model(model, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSw3FwtiDmlv",
        "outputId": "8a71ccfa-5d95-46bd-9931-01814bcec741"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 0.9493, Val Loss: 0.6509\n",
            "Epoch 2/50, Loss: 0.6553, Val Loss: 0.6006\n",
            "Epoch 3/50, Loss: 0.6452, Val Loss: 0.6108\n",
            "Epoch 4/50, Loss: 0.6282, Val Loss: 0.5757\n",
            "Epoch 5/50, Loss: 0.6093, Val Loss: 0.5643\n",
            "Epoch 6/50, Loss: 0.6113, Val Loss: 0.5713\n",
            "Epoch 7/50, Loss: 0.5954, Val Loss: 0.5605\n",
            "Epoch 8/50, Loss: 0.5860, Val Loss: 0.5746\n",
            "Epoch 9/50, Loss: 0.6192, Val Loss: 0.6229\n",
            "Epoch 10/50, Loss: 0.6200, Val Loss: 0.5520\n",
            "Epoch 11/50, Loss: 0.5769, Val Loss: 0.5337\n",
            "Epoch 12/50, Loss: 0.5883, Val Loss: 0.5203\n",
            "Epoch 13/50, Loss: 0.5484, Val Loss: 0.5549\n",
            "Epoch 14/50, Loss: 0.5684, Val Loss: 0.4942\n",
            "Epoch 15/50, Loss: 0.5786, Val Loss: 0.5372\n",
            "Epoch 16/50, Loss: 0.5542, Val Loss: 0.5031\n",
            "Epoch 17/50, Loss: 0.5474, Val Loss: 0.4874\n",
            "Epoch 18/50, Loss: 0.5178, Val Loss: 0.4962\n",
            "Epoch 19/50, Loss: 0.5240, Val Loss: 0.4883\n",
            "Epoch 20/50, Loss: 0.5143, Val Loss: 0.5004\n",
            "Epoch 21/50, Loss: 0.5226, Val Loss: 0.4970\n",
            "Epoch 22/50, Loss: 0.5109, Val Loss: 0.4796\n",
            "Epoch 23/50, Loss: 0.5033, Val Loss: 0.4806\n",
            "Epoch 24/50, Loss: 0.4847, Val Loss: 0.4586\n",
            "Epoch 25/50, Loss: 0.4947, Val Loss: 0.4795\n",
            "Epoch 26/50, Loss: 0.4963, Val Loss: 0.4558\n",
            "Epoch 27/50, Loss: 0.4863, Val Loss: 0.4829\n",
            "Epoch 28/50, Loss: 0.4906, Val Loss: 0.4601\n",
            "Epoch 29/50, Loss: 0.5067, Val Loss: 0.4819\n",
            "Epoch 30/50, Loss: 0.4955, Val Loss: 0.4445\n",
            "Epoch 31/50, Loss: 0.4979, Val Loss: 0.4760\n",
            "Epoch 32/50, Loss: 0.4840, Val Loss: 0.4935\n",
            "Epoch 33/50, Loss: 0.4683, Val Loss: 0.4507\n",
            "Epoch 34/50, Loss: 0.4861, Val Loss: 0.4647\n",
            "Epoch 35/50, Loss: 0.4881, Val Loss: 0.4431\n",
            "Epoch 36/50, Loss: 0.4772, Val Loss: 0.4672\n",
            "Epoch 37/50, Loss: 0.4803, Val Loss: 0.4662\n",
            "Epoch 38/50, Loss: 0.4698, Val Loss: 0.4726\n",
            "Epoch 39/50, Loss: 0.4592, Val Loss: 0.4541\n",
            "Epoch 40/50, Loss: 0.4828, Val Loss: 0.4655\n",
            "Epoch 41/50, Loss: 0.4776, Val Loss: 0.4502\n",
            "Epoch 42/50, Loss: 0.4745, Val Loss: 0.4678\n",
            "Epoch 43/50, Loss: 0.4579, Val Loss: 0.4407\n",
            "Epoch 44/50, Loss: 0.4691, Val Loss: 0.4830\n",
            "Epoch 45/50, Loss: 0.4627, Val Loss: 0.4399\n",
            "Epoch 46/50, Loss: 0.4354, Val Loss: 0.4538\n",
            "Epoch 47/50, Loss: 0.4556, Val Loss: 0.4654\n",
            "Epoch 48/50, Loss: 0.4952, Val Loss: 0.5008\n",
            "Epoch 49/50, Loss: 0.4598, Val Loss: 0.4996\n",
            "Epoch 50/50, Loss: 0.4796, Val Loss: 0.4659\n",
            "Accuracy: 0.7989\n",
            "Precision: 0.7879\n",
            "Recall: 0.7027\n",
            "F1 Score: 0.7429\n",
            "ROC-AUC: 0.7847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наибольшего результата roc-auc удалось добиться 0.8, хотя оно скачет от 0.74 до 0.8."
      ],
      "metadata": {
        "id": "NrwBSsHRW4Kc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сформируем файл для загрузки на сайт."
      ],
      "metadata": {
        "id": "ZGwQhggFWRZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_submission_file(model, test_df, original_test_df, output_file='submission.csv'):\n",
        "    model.eval()\n",
        "    test_tensor = torch.tensor(test_df.values.astype('float32'))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predictions = model(test_tensor)\n",
        "        predictions = (predictions >= 0.5).float().numpy()\n",
        "\n",
        "    submission_df = pd.DataFrame({\n",
        "        'PassengerId': original_test_df['PassengerId'],\n",
        "        'Survived': predictions.flatten().astype(int)\n",
        "    })\n",
        "\n",
        "    submission_df.to_csv(output_file, index=False)\n",
        "\n",
        "original_test_df = pd.read_csv('test.csv')\n",
        "\n",
        "generate_submission_file(model, test_df, original_test_df, output_file='submission.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjgeHhh8Tg4l",
        "outputId": "69ba5bcb-b61b-447a-eadc-b4605b40a57a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file saved as submission.csv\n"
          ]
        }
      ]
    }
  ]
}